{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/pranavgajera/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/pranavgajera/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from embeddings import GloveEmbedding, FastTextEmbedding, KazumaCharEmbedding, ConcatEmbedding\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nlppreprocess import NLP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = GloveEmbedding('common_crawl_840', d_emb=300, show_progress=True,default='zero' )\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nlp = NLP()\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "negative_stopwords = [\"no\", \"not\", \"never\", \"none\", \"nothing\", \"nobody\"]\n",
    "stopwords = [word for word in stopwords if word not in negative_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset=1):\n",
    "    if(dataset==1):\n",
    "        train_df = pd.read_excel('./Dataset/ClassificationDataset-train0.xlsx',header=None).dropna()\n",
    "        val_df = pd.read_excel('./Dataset/ClassificationDataset-valid0.xlsx',header=None).dropna()\n",
    "        train_df.columns = ['target','sentiment']\n",
    "        val_df.columns = ['target','sentiment']\n",
    "    elif(dataset==2):\n",
    "        train_df = pd.read_excel('./Dataset/ClassificationDataset-train1.xlsx').dropna()\n",
    "        val_df = pd.read_excel('./Dataset/ClassificationDataset-valid1.xlsx').dropna()\n",
    "    elif(dataset==3):\n",
    "        train_df = pd.read_excel('./Dataset/ClassificationDataset-train2.xlsx').dropna()\n",
    "        val_df = pd.read_excel('./Dataset/ClassificationDataset-valid2.xlsx').dropna()\n",
    "        \n",
    "    return  train_df,val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_to_cummulative_embedding(message):\n",
    "    tokens = tokenizer.tokenize(nlp.process(message))\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    useful_words = [t for t in lemmatized_tokens if t.lower() not in stopwords]\n",
    "    \n",
    "    embedding_vector = np.zeros((glove_embeddings.d_emb))\n",
    "    for word in useful_words:\n",
    "        word_embedding = glove_embeddings.emb(word)\n",
    "        embedding_vector = np.add(embedding_vector,word_embedding)\n",
    "    \n",
    "    return embedding_vector\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(dataset=1):\n",
    "    train_df, val_df = load_dataset(dataset)\n",
    "\n",
    "    X_train = train_df.iloc[:,1]\n",
    "    y_train = train_df.iloc[:,0]\n",
    "    X_val = val_df.iloc[:,1]\n",
    "    y_val = val_df.iloc[:,0]\n",
    "\n",
    "    if(dataset==1):\n",
    "        y_train = [np.array([1,0,0]) if y=='negative' else np.array([0,1,0]) if y=='neutral' else np.array([0,0,1]) for y in y_train]\n",
    "        y_val = [np.array([1,0,0]) if y=='negative' else np.array([0,1,0]) if y=='neutral' else np.array([0,0,1]) for y in y_val]\n",
    "    elif(dataset==2):\n",
    "        y_train = [np.array([1,0]) if y==0 else np.array([0,1]) for y in y_train]\n",
    "        y_val = [np.array([1,0]) if y==0 else np.array([0,1]) for y in y_val]\n",
    "    elif(dataset==3):\n",
    "        y_train = [np.array([1,0,0,0,0]) if y==1 else np.array([0,1,0,0,0]) if y==2 else np.array([0,0,1,0,0]) if y==3 else np.array([0,0,0,1,0]) if y==4 else np.array([0,0,0,0,1]) for y in y_train]\n",
    "        y_val = [np.array([1,0,0,0,0]) if y==1 else np.array([0,1,0,0,0]) if y==2 else np.array([0,0,1,0,0]) if y==3 else np.array([0,0,0,1,0]) if y==4 else np.array([0,0,0,0,1]) for y in y_val]\n",
    "\n",
    "    X_train = [message_to_cummulative_embedding(m) for m in X_train]\n",
    "    X_val = [message_to_cummulative_embedding(m) for m in X_val]\n",
    "\n",
    "    return np.array(X_train),np.array(X_val),np.array(y_train),np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DANSentimentClassifier(nn.Module):\n",
    "    def __init__(self,input_dim,hidden1_dim,hidden2_dim,hidden3_dim,drop_out1,drop_out2,drop_out3,num_classes):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,hidden1_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(drop_out1)\n",
    "        self.layer2 = nn.Linear(hidden1_dim,hidden2_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(drop_out2)\n",
    "        self.layer3 = nn.Linear(hidden2_dim,hidden3_dim)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(drop_out3)\n",
    "        self.out = nn.Linear(hidden3_dim,num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = F.softmax(self.out(x),dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, epochs, lr):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_accu = list()\n",
    "    val_acuu = list()\n",
    "    epoch_list = list()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_list.append(epoch+1)\n",
    "        correct = 0\n",
    "        inputs, labels = train_data\n",
    "        inputs = torch.tensor(inputs,dtype=torch.float32)\n",
    "        labels = torch.tensor(labels,dtype=torch.float32)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        predictions = outputs.argmax(dim=-1)\n",
    "        labels = labels.argmax(dim=-1)\n",
    "        correct += (predictions==labels).sum().item()\n",
    "        train_accuracy = correct/inputs.shape[0]\n",
    "        train_accu.append(train_accuracy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = val_data\n",
    "            inputs = torch.tensor(inputs,dtype=torch.float32)\n",
    "            labels = torch.tensor(labels,dtype=torch.float32)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            predictions = outputs.argmax(dim=-1)\n",
    "            labels = labels.argmax(dim=-1)\n",
    "            correct += (predictions==labels).sum().item()\n",
    "            val_accuracy = correct/inputs.shape[0]\n",
    "            val_acuu.append(val_accuracy)\n",
    "            f1_score = sklearn.metrics.f1_score(labels, predictions,average='micro')\n",
    "            confusion_matrix = sklearn.metrics.confusion_matrix(labels, predictions)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train loss {loss}, Val loss {val_loss}, Train acc {train_accuracy} , Val acc {val_accuracy}, F1-Score {f1_score}\")\n",
    "    print(\"Confusion Matrix :\")\n",
    "    print(confusion_matrix)\n",
    "    print()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: Train loss {loss}, Val loss {val_loss}, Train acc {train_accuracy} , Val acc {val_accuracy}, F1-Score {f1_score}\")\n",
    "\n",
    "    plt.plot(epoch_list, train_accu)\n",
    "    plt.plot(epoch_list,val_acuu)\n",
    "    plt.xlabel(\"Epochs\") \n",
    "    plt.ylabel(\"Acccuracy\") \n",
    "    plt.title(f\"Train and Validation Accuracy for dataset {dataset}\") \n",
    "    plt.legend([\"Train\",\"Validation\"])\n",
    "    plt.savefig(f'dataset_{dataset}.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350: Train loss 0.7015745639801025, Val loss 0.6887186765670776, Train acc 0.4935921248142645 , Val acc 0.546780345523895, F1-Score 0.546780345523895\n",
      "Epoch 2/350: Train loss 0.6881521344184875, Val loss 0.6819140911102295, Train acc 0.5667719167904903 , Val acc 0.6073592102310972, F1-Score 0.6073592102310972\n",
      "Epoch 3/350: Train loss 0.6775531768798828, Val loss 0.66934734582901, Train acc 0.611905646359584 , Val acc 0.6419115997307606, F1-Score 0.6419115997307606\n",
      "Epoch 4/350: Train loss 0.6638867259025574, Val loss 0.6560646891593933, Train acc 0.6720839524517088 , Val acc 0.6932914516490913, F1-Score 0.6932914516490913\n",
      "Epoch 5/350: Train loss 0.6471225023269653, Val loss 0.6405969262123108, Train acc 0.7176820208023774 , Val acc 0.7195422930222123, F1-Score 0.7195422930222123\n",
      "Epoch 6/350: Train loss 0.6283113360404968, Val loss 0.6264030933380127, Train acc 0.7534361069836553 , Val acc 0.7361453892752973, F1-Score 0.7361453892752973\n",
      "Epoch 7/350: Train loss 0.6082906723022461, Val loss 0.6033009886741638, Train acc 0.7840824665676077 , Val acc 0.78169172088849, F1-Score 0.7816917208884901\n",
      "Epoch 8/350: Train loss 0.5869810581207275, Val loss 0.5880520939826965, Train acc 0.8107355126300149 , Val acc 0.7868521426968813, F1-Score 0.7868521426968813\n",
      "Epoch 9/350: Train loss 0.5658113956451416, Val loss 0.5702760219573975, Train acc 0.8277303120356612 , Val acc 0.8061476329369531, F1-Score 0.806147632936953\n",
      "Epoch 10/350: Train loss 0.547137439250946, Val loss 0.5527109503746033, Train acc 0.8387815750371471 , Val acc 0.8135517164011667, F1-Score 0.8135517164011667\n",
      "Epoch 11/350: Train loss 0.5262694954872131, Val loss 0.5341282486915588, Train acc 0.8520616641901931 , Val acc 0.8256674893426071, F1-Score 0.8256674893426071\n",
      "Epoch 12/350: Train loss 0.512475848197937, Val loss 0.5207698941230774, Train acc 0.8560549777117384 , Val acc 0.8256674893426071, F1-Score 0.8256674893426071\n",
      "Epoch 13/350: Train loss 0.49536290764808655, Val loss 0.508248507976532, Train acc 0.8606054977711739 , Val acc 0.8344177698003141, F1-Score 0.8344177698003141\n",
      "Epoch 14/350: Train loss 0.4813303053379059, Val loss 0.4978492259979248, Train acc 0.8697994056463596 , Val acc 0.8454117119138433, F1-Score 0.8454117119138435\n",
      "Epoch 15/350: Train loss 0.47040602564811707, Val loss 0.48945385217666626, Train acc 0.87481426448737 , Val acc 0.8420462194301099, F1-Score 0.8420462194301099\n",
      "Epoch 16/350: Train loss 0.4576042890548706, Val loss 0.4745083749294281, Train acc 0.8775074294205052 , Val acc 0.8530401615436393, F1-Score 0.8530401615436393\n",
      "Epoch 17/350: Train loss 0.4470840096473694, Val loss 0.4723297357559204, Train acc 0.8847511144130757 , Val acc 0.8494503028943236, F1-Score 0.8494503028943234\n",
      "Epoch 18/350: Train loss 0.4418467879295349, Val loss 0.46513134241104126, Train acc 0.8862369985141159 , Val acc 0.854835090868297, F1-Score 0.8548350908682971\n",
      "Epoch 19/350: Train loss 0.43534237146377563, Val loss 0.4617026150226593, Train acc 0.8891158989598811 , Val acc 0.8550594570338793, F1-Score 0.8550594570338793\n",
      "Epoch 20/350: Train loss 0.4312170147895813, Val loss 0.4549804925918579, Train acc 0.8931092124814265 , Val acc 0.8584249495176127, F1-Score 0.8584249495176127\n",
      "Epoch 21/350: Train loss 0.4271073341369629, Val loss 0.44834786653518677, Train acc 0.8941307578008916 , Val acc 0.869418891631142, F1-Score 0.8694188916311422\n",
      "Epoch 22/350: Train loss 0.42116737365722656, Val loss 0.4477181136608124, Train acc 0.8971953937592868 , Val acc 0.8633610051604218, F1-Score 0.8633610051604218\n",
      "Epoch 23/350: Train loss 0.41828757524490356, Val loss 0.4466194808483124, Train acc 0.8980312035661219 , Val acc 0.8640341036571685, F1-Score 0.8640341036571685\n",
      "Epoch 24/350: Train loss 0.41411107778549194, Val loss 0.44287770986557007, Train acc 0.9013744427934621 , Val acc 0.8691945254655598, F1-Score 0.8691945254655598\n",
      "Epoch 25/350: Train loss 0.41405189037323, Val loss 0.4398704767227173, Train acc 0.900352897473997 , Val acc 0.8707650886246354, F1-Score 0.8707650886246354\n",
      "Epoch 26/350: Train loss 0.40933820605278015, Val loss 0.4394684135913849, Train acc 0.9043462109955424 , Val acc 0.8705407224590532, F1-Score 0.8705407224590531\n",
      "Epoch 27/350: Train loss 0.4088509678840637, Val loss 0.4359298348426819, Train acc 0.9037890044576523 , Val acc 0.8734574826116221, F1-Score 0.8734574826116223\n",
      "Epoch 28/350: Train loss 0.40945249795913696, Val loss 0.4345821738243103, Train acc 0.9041604754829123 , Val acc 0.87525241193628, F1-Score 0.87525241193628\n",
      "Epoch 29/350: Train loss 0.4034346342086792, Val loss 0.43326398730278015, Train acc 0.9087109955423477 , Val acc 0.8765986089297734, F1-Score 0.8765986089297734\n",
      "Epoch 30/350: Train loss 0.40286552906036377, Val loss 0.4315968155860901, Train acc 0.9091753343239227 , Val acc 0.8774960735921024, F1-Score 0.8774960735921024\n",
      "Epoch 31/350: Train loss 0.40172237157821655, Val loss 0.432085245847702, Train acc 0.9098254086181278 , Val acc 0.8768229750953557, F1-Score 0.8768229750953557\n",
      "Epoch 32/350: Train loss 0.40260058641433716, Val loss 0.4318823516368866, Train acc 0.9088967310549777 , Val acc 0.8770473412609379, F1-Score 0.8770473412609379\n",
      "Epoch 33/350: Train loss 0.4011692404747009, Val loss 0.42541348934173584, Train acc 0.9096396731054978 , Val acc 0.8851245232218982, F1-Score 0.8851245232218982\n",
      "Epoch 34/350: Train loss 0.39828136563301086, Val loss 0.4248220920562744, Train acc 0.9140044576523031 , Val acc 0.8849001570563159, F1-Score 0.8849001570563159\n",
      "Epoch 35/350: Train loss 0.39753395318984985, Val loss 0.4260210692882538, Train acc 0.9144687964338781 , Val acc 0.8842270585595692, F1-Score 0.8842270585595692\n",
      "Epoch 36/350: Train loss 0.39880675077438354, Val loss 0.4244234561920166, Train acc 0.912332838038633 , Val acc 0.8828808615660758, F1-Score 0.8828808615660759\n",
      "Epoch 37/350: Train loss 0.3955177962779999, Val loss 0.4226442575454712, Train acc 0.9167904903417533 , Val acc 0.8871438187121382, F1-Score 0.8871438187121382\n",
      "Epoch 38/350: Train loss 0.39623215794563293, Val loss 0.42379656434059143, Train acc 0.9140973254086181 , Val acc 0.8849001570563159, F1-Score 0.8849001570563159\n",
      "Epoch 39/350: Train loss 0.39465785026550293, Val loss 0.4235154688358307, Train acc 0.9166976225854383 , Val acc 0.8853488893874804, F1-Score 0.8853488893874805\n",
      "Epoch 40/350: Train loss 0.39459481835365295, Val loss 0.42433273792266846, Train acc 0.9171619613670133 , Val acc 0.8826564954004936, F1-Score 0.8826564954004936\n",
      "Epoch 41/350: Train loss 0.393500953912735, Val loss 0.4258366525173187, Train acc 0.9179977711738484 , Val acc 0.8835539600628225, F1-Score 0.8835539600628225\n",
      "Epoch 42/350: Train loss 0.3943063020706177, Val loss 0.42380714416503906, Train acc 0.9170690936106983 , Val acc 0.8851245232218982, F1-Score 0.8851245232218982\n",
      "Epoch 43/350: Train loss 0.391740083694458, Val loss 0.42258667945861816, Train acc 0.9194836552748885 , Val acc 0.886919452546556, F1-Score 0.886919452546556\n",
      "Epoch 44/350: Train loss 0.3924568295478821, Val loss 0.423591673374176, Train acc 0.9183692421991084 , Val acc 0.8837783262284048, F1-Score 0.8837783262284048\n",
      "Epoch 45/350: Train loss 0.3915306329727173, Val loss 0.4194587469100952, Train acc 0.9197622585438335 , Val acc 0.8907336773614539, F1-Score 0.8907336773614539\n",
      "Epoch 46/350: Train loss 0.3915676474571228, Val loss 0.41724342107772827, Train acc 0.9195765230312035 , Val acc 0.8936504375140228, F1-Score 0.8936504375140228\n",
      "Epoch 47/350: Train loss 0.390468567609787, Val loss 0.4192298352718353, Train acc 0.9200408618127786 , Val acc 0.8893874803679606, F1-Score 0.8893874803679606\n",
      "Epoch 48/350: Train loss 0.3908969461917877, Val loss 0.4200792610645294, Train acc 0.9204123328380386 , Val acc 0.8898362126991249, F1-Score 0.8898362126991249\n",
      "Epoch 49/350: Train loss 0.389942467212677, Val loss 0.41893383860588074, Train acc 0.9213410104011887 , Val acc 0.8907336773614539, F1-Score 0.8907336773614539\n",
      "Epoch 50/350: Train loss 0.39005184173583984, Val loss 0.4182513952255249, Train acc 0.9214338781575037 , Val acc 0.8918555081893651, F1-Score 0.8918555081893651\n",
      "Epoch 51/350: Train loss 0.38922008872032166, Val loss 0.41632694005966187, Train acc 0.9222696879643388 , Val acc 0.8940991698451873, F1-Score 0.8940991698451873\n",
      "Epoch 52/350: Train loss 0.38903772830963135, Val loss 0.41960445046424866, Train acc 0.9219910846953938 , Val acc 0.8887143818712138, F1-Score 0.8887143818712138\n",
      "Epoch 53/350: Train loss 0.38826924562454224, Val loss 0.41467148065567017, Train acc 0.9229197622585439 , Val acc 0.8958940991698452, F1-Score 0.8958940991698451\n",
      "Epoch 54/350: Train loss 0.38748258352279663, Val loss 0.4164150357246399, Train acc 0.9234769687964339 , Val acc 0.8936504375140228, F1-Score 0.8936504375140228\n",
      "Epoch 55/350: Train loss 0.38810229301452637, Val loss 0.4172719717025757, Train acc 0.9229197622585439 , Val acc 0.8900605788647072, F1-Score 0.8900605788647072\n",
      "Epoch 56/350: Train loss 0.38688021898269653, Val loss 0.41723522543907166, Train acc 0.924127043090639 , Val acc 0.8923042405205295, F1-Score 0.8923042405205295\n",
      "Epoch 57/350: Train loss 0.38734138011932373, Val loss 0.4163149297237396, Train acc 0.923941307578009 , Val acc 0.8929773390172762, F1-Score 0.8929773390172762\n",
      "Epoch 58/350: Train loss 0.3871168792247772, Val loss 0.4146573841571808, Train acc 0.924405646359584 , Val acc 0.8949966345075163, F1-Score 0.8949966345075163\n",
      "Epoch 59/350: Train loss 0.386966347694397, Val loss 0.41661107540130615, Train acc 0.923941307578009 , Val acc 0.8920798743549473, F1-Score 0.8920798743549473\n",
      "Epoch 60/350: Train loss 0.38662248849868774, Val loss 0.41643932461738586, Train acc 0.924962852897474 , Val acc 0.8938748036796051, F1-Score 0.8938748036796051\n",
      "Epoch 61/350: Train loss 0.3845345079898834, Val loss 0.4152831733226776, Train acc 0.9263558692421991 , Val acc 0.8925286066861118, F1-Score 0.8925286066861118\n",
      "Epoch 62/350: Train loss 0.3855849802494049, Val loss 0.41423943638801575, Train acc 0.9254271916790491 , Val acc 0.8954453668386807, F1-Score 0.8954453668386808\n",
      "Epoch 63/350: Train loss 0.38508185744285583, Val loss 0.413867712020874, Train acc 0.9260772659732541 , Val acc 0.894772268341934, F1-Score 0.8947722683419341\n",
      "Epoch 64/350: Train loss 0.3848910629749298, Val loss 0.4149545431137085, Train acc 0.9260772659732541 , Val acc 0.8932017051828585, F1-Score 0.8932017051828585\n",
      "Epoch 65/350: Train loss 0.3841351270675659, Val loss 0.4122813940048218, Train acc 0.9274702823179792 , Val acc 0.8945479021763518, F1-Score 0.8945479021763518\n",
      "Epoch 66/350: Train loss 0.3817676603794098, Val loss 0.4105159044265747, Train acc 0.9296062407132244 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 67/350: Train loss 0.3824668824672699, Val loss 0.41274598240852356, Train acc 0.9288632986627043 , Val acc 0.8961184653354274, F1-Score 0.8961184653354274\n",
      "Epoch 68/350: Train loss 0.38210710883140564, Val loss 0.41438546776771545, Train acc 0.9295133729569094 , Val acc 0.8954453668386807, F1-Score 0.8954453668386808\n",
      "Epoch 69/350: Train loss 0.3822872042655945, Val loss 0.41307419538497925, Train acc 0.9295133729569094 , Val acc 0.8970159299977564, F1-Score 0.8970159299977564\n",
      "Epoch 70/350: Train loss 0.383517861366272, Val loss 0.4119703471660614, Train acc 0.9275631500742942 , Val acc 0.8985864931568319, F1-Score 0.8985864931568318\n",
      "Epoch 71/350: Train loss 0.38041067123413086, Val loss 0.41166022419929504, Train acc 0.9322994056463596 , Val acc 0.8985864931568319, F1-Score 0.8985864931568318\n",
      "Epoch 72/350: Train loss 0.38019055128097534, Val loss 0.41303277015686035, Train acc 0.9325780089153046 , Val acc 0.8979133946600852, F1-Score 0.8979133946600852\n",
      "Epoch 73/350: Train loss 0.38138115406036377, Val loss 0.41096001863479614, Train acc 0.9314635958395245 , Val acc 0.8994839578191609, F1-Score 0.8994839578191608\n",
      "Epoch 74/350: Train loss 0.38104379177093506, Val loss 0.4112440347671509, Train acc 0.9320208023774146 , Val acc 0.8992595916535786, F1-Score 0.8992595916535786\n",
      "Epoch 75/350: Train loss 0.37942802906036377, Val loss 0.4123743176460266, Train acc 0.9327637444279346 , Val acc 0.8965671976665919, F1-Score 0.8965671976665919\n",
      "Epoch 76/350: Train loss 0.3787393867969513, Val loss 0.41356828808784485, Train acc 0.9332280832095097 , Val acc 0.8958940991698452, F1-Score 0.8958940991698451\n",
      "Epoch 77/350: Train loss 0.37958842515945435, Val loss 0.4135619103908539, Train acc 0.9329494799405647 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 78/350: Train loss 0.37917810678482056, Val loss 0.41280531883239746, Train acc 0.9334138187221397 , Val acc 0.8965671976665919, F1-Score 0.8965671976665919\n",
      "Epoch 79/350: Train loss 0.37798887491226196, Val loss 0.4110001027584076, Train acc 0.9350854383358098 , Val acc 0.8999326901503253, F1-Score 0.8999326901503253\n",
      "Epoch 80/350: Train loss 0.3785818815231323, Val loss 0.4129372239112854, Train acc 0.9346210995542348 , Val acc 0.8970159299977564, F1-Score 0.8970159299977564\n",
      "Epoch 81/350: Train loss 0.37756723165512085, Val loss 0.4119202792644501, Train acc 0.9350854383358098 , Val acc 0.8988108593224142, F1-Score 0.8988108593224142\n",
      "Epoch 82/350: Train loss 0.37794074416160583, Val loss 0.41278019547462463, Train acc 0.9349925705794948 , Val acc 0.8972402961633386, F1-Score 0.8972402961633386\n",
      "Epoch 83/350: Train loss 0.37814268469810486, Val loss 0.41196146607398987, Train acc 0.9349925705794948 , Val acc 0.8992595916535786, F1-Score 0.8992595916535786\n",
      "Epoch 84/350: Train loss 0.37769439816474915, Val loss 0.4121559262275696, Train acc 0.9353640416047548 , Val acc 0.8965671976665919, F1-Score 0.8965671976665919\n",
      "Epoch 85/350: Train loss 0.37712740898132324, Val loss 0.4107134938240051, Train acc 0.9355497771173849 , Val acc 0.9001570563159076, F1-Score 0.9001570563159076\n",
      "Epoch 86/350: Train loss 0.3755629360675812, Val loss 0.4117361307144165, Train acc 0.937035661218425 , Val acc 0.8983621269912497, F1-Score 0.8983621269912498\n",
      "Epoch 87/350: Train loss 0.37590450048446655, Val loss 0.41353097558021545, Train acc 0.9360141158989599 , Val acc 0.8963428315010097, F1-Score 0.8963428315010097\n",
      "Epoch 88/350: Train loss 0.37520405650138855, Val loss 0.41172826290130615, Train acc 0.937592867756315 , Val acc 0.8990352254879964, F1-Score 0.8990352254879964\n",
      "Epoch 89/350: Train loss 0.3751590847969055, Val loss 0.4096032679080963, Train acc 0.937407132243685 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 90/350: Train loss 0.37380456924438477, Val loss 0.4113612771034241, Train acc 0.9388001485884101 , Val acc 0.8992595916535786, F1-Score 0.8992595916535786\n",
      "Epoch 91/350: Train loss 0.3752722442150116, Val loss 0.41018518805503845, Train acc 0.9375 , Val acc 0.8990352254879964, F1-Score 0.8990352254879964\n",
      "Epoch 92/350: Train loss 0.3745094835758209, Val loss 0.40942317247390747, Train acc 0.93787147102526 , Val acc 0.903522548799641, F1-Score 0.903522548799641\n",
      "Epoch 93/350: Train loss 0.37277841567993164, Val loss 0.4100866913795471, Train acc 0.9401931649331352 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 94/350: Train loss 0.3738577961921692, Val loss 0.41109853982925415, Train acc 0.9386144130757801 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 95/350: Train loss 0.3733753263950348, Val loss 0.40867483615875244, Train acc 0.9391716196136701 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 96/350: Train loss 0.3737393915653229, Val loss 0.41132521629333496, Train acc 0.9399145616641902 , Val acc 0.8988108593224142, F1-Score 0.8988108593224142\n",
      "Epoch 97/350: Train loss 0.3732716143131256, Val loss 0.40968838334083557, Train acc 0.9388001485884101 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 98/350: Train loss 0.3705001771450043, Val loss 0.40877604484558105, Train acc 0.9413075780089153 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 99/350: Train loss 0.37058714032173157, Val loss 0.40947166085243225, Train acc 0.9425148588410104 , Val acc 0.8999326901503253, F1-Score 0.8999326901503253\n",
      "Epoch 100/350: Train loss 0.3716580271720886, Val loss 0.4093649089336395, Train acc 0.9410289747399703 , Val acc 0.901503253309401, F1-Score 0.901503253309401\n",
      "Epoch 101/350: Train loss 0.3710770010948181, Val loss 0.40757349133491516, Train acc 0.9418647845468053 , Val acc 0.9037469149652232, F1-Score 0.9037469149652232\n",
      "Epoch 102/350: Train loss 0.37137165665626526, Val loss 0.4112689197063446, Train acc 0.9419576523031203 , Val acc 0.8988108593224142, F1-Score 0.8988108593224142\n",
      "Epoch 103/350: Train loss 0.3704390823841095, Val loss 0.4095993936061859, Train acc 0.9427934621099554 , Val acc 0.9021763518061476, F1-Score 0.9021763518061476\n",
      "Epoch 104/350: Train loss 0.37168848514556885, Val loss 0.4105337858200073, Train acc 0.9412147102526003 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 105/350: Train loss 0.3694443106651306, Val loss 0.41224291920661926, Train acc 0.9433506686478454 , Val acc 0.8983621269912497, F1-Score 0.8983621269912498\n",
      "Epoch 106/350: Train loss 0.36923086643218994, Val loss 0.40873298048973083, Train acc 0.9440007429420505 , Val acc 0.9010545209782365, F1-Score 0.9010545209782365\n",
      "Epoch 107/350: Train loss 0.3693206012248993, Val loss 0.4094090759754181, Train acc 0.9444650817236255 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 108/350: Train loss 0.36951398849487305, Val loss 0.41166362166404724, Train acc 0.9435364041604755 , Val acc 0.8985864931568319, F1-Score 0.8985864931568318\n",
      "Epoch 109/350: Train loss 0.3703855574131012, Val loss 0.40877625346183777, Train acc 0.9427005943536404 , Val acc 0.9028494503028943, F1-Score 0.9028494503028943\n",
      "Epoch 110/350: Train loss 0.37026360630989075, Val loss 0.4068785011768341, Train acc 0.9427005943536404 , Val acc 0.90442001346197, F1-Score 0.90442001346197\n",
      "Epoch 111/350: Train loss 0.36816340684890747, Val loss 0.40951624512672424, Train acc 0.9444650817236255 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 112/350: Train loss 0.3677542209625244, Val loss 0.4079548716545105, Train acc 0.9453937592867756 , Val acc 0.9030738164684765, F1-Score 0.9030738164684765\n",
      "Epoch 113/350: Train loss 0.36867088079452515, Val loss 0.4076854884624481, Train acc 0.9439078751857355 , Val acc 0.9039712811308055, F1-Score 0.9039712811308055\n",
      "Epoch 114/350: Train loss 0.36752551794052124, Val loss 0.4082915782928467, Train acc 0.9453008915304606 , Val acc 0.901503253309401, F1-Score 0.901503253309401\n",
      "Epoch 115/350: Train loss 0.36786016821861267, Val loss 0.40884631872177124, Train acc 0.9452080237741456 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 116/350: Train loss 0.3671654462814331, Val loss 0.40932947397232056, Train acc 0.9466010401188707 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 117/350: Train loss 0.3662108778953552, Val loss 0.409533828496933, Train acc 0.9465081723625557 , Val acc 0.9026250841373121, F1-Score 0.9026250841373121\n",
      "Epoch 118/350: Train loss 0.36668631434440613, Val loss 0.40930578112602234, Train acc 0.9468796433878157 , Val acc 0.9021763518061476, F1-Score 0.9021763518061476\n",
      "Epoch 119/350: Train loss 0.36589160561561584, Val loss 0.40727996826171875, Train acc 0.9476225854383358 , Val acc 0.9032981826340588, F1-Score 0.9032981826340588\n",
      "Epoch 120/350: Train loss 0.3663025498390198, Val loss 0.4070219099521637, Train acc 0.9466939078751857 , Val acc 0.9039712811308055, F1-Score 0.9039712811308055\n",
      "Epoch 121/350: Train loss 0.36594870686531067, Val loss 0.40977030992507935, Train acc 0.9475297176820208 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 122/350: Train loss 0.36450275778770447, Val loss 0.4098500907421112, Train acc 0.9497585438335809 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 123/350: Train loss 0.3640093207359314, Val loss 0.40907347202301025, Train acc 0.950130014858841 , Val acc 0.901503253309401, F1-Score 0.901503253309401\n",
      "Epoch 124/350: Train loss 0.36522796750068665, Val loss 0.4089609384536743, Train acc 0.9479940564635958 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 125/350: Train loss 0.3648884892463684, Val loss 0.4073929190635681, Train acc 0.9486441307578009 , Val acc 0.9030738164684765, F1-Score 0.9030738164684765\n",
      "Epoch 126/350: Train loss 0.36405447125434875, Val loss 0.4096602499485016, Train acc 0.9493870728083209 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 127/350: Train loss 0.3644506633281708, Val loss 0.41192594170570374, Train acc 0.9492013372956909 , Val acc 0.8974646623289207, F1-Score 0.8974646623289209\n",
      "Epoch 128/350: Train loss 0.36443307995796204, Val loss 0.40986159443855286, Train acc 0.9493870728083209 , Val acc 0.8988108593224142, F1-Score 0.8988108593224142\n",
      "Epoch 129/350: Train loss 0.36360493302345276, Val loss 0.41050615906715393, Train acc 0.9491084695393759 , Val acc 0.8999326901503253, F1-Score 0.8999326901503253\n",
      "Epoch 130/350: Train loss 0.3623269200325012, Val loss 0.4115321934223175, Train acc 0.951244427934621 , Val acc 0.8992595916535786, F1-Score 0.8992595916535786\n",
      "Epoch 131/350: Train loss 0.3636032044887543, Val loss 0.4069775342941284, Train acc 0.950037147102526 , Val acc 0.903522548799641, F1-Score 0.903522548799641\n",
      "Epoch 132/350: Train loss 0.36147862672805786, Val loss 0.40936145186424255, Train acc 0.9530089153046062 , Val acc 0.8999326901503253, F1-Score 0.8999326901503253\n",
      "Epoch 133/350: Train loss 0.36237478256225586, Val loss 0.4110337793827057, Train acc 0.950315750371471 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 134/350: Train loss 0.36242055892944336, Val loss 0.4088246822357178, Train acc 0.950687221396731 , Val acc 0.9021763518061476, F1-Score 0.9021763518061476\n",
      "Epoch 135/350: Train loss 0.36178717017173767, Val loss 0.4088345468044281, Train acc 0.9518016344725111 , Val acc 0.9010545209782365, F1-Score 0.9010545209782365\n",
      "Epoch 136/350: Train loss 0.36110761761665344, Val loss 0.4102625846862793, Train acc 0.9523588410104011 , Val acc 0.9010545209782365, F1-Score 0.9010545209782365\n",
      "Epoch 137/350: Train loss 0.36238300800323486, Val loss 0.40780913829803467, Train acc 0.951058692421991 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 138/350: Train loss 0.3621900677680969, Val loss 0.409088671207428, Train acc 0.951151560178306 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 139/350: Train loss 0.3609289526939392, Val loss 0.41030004620552063, Train acc 0.9523588410104011 , Val acc 0.8997083239847431, F1-Score 0.8997083239847431\n",
      "Epoch 140/350: Train loss 0.3610150218009949, Val loss 0.40895771980285645, Train acc 0.9527303120356612 , Val acc 0.9008301548126543, F1-Score 0.9008301548126543\n",
      "Epoch 141/350: Train loss 0.3605237305164337, Val loss 0.40957581996917725, Train acc 0.9533803863298663 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 142/350: Train loss 0.3604600131511688, Val loss 0.41045135259628296, Train acc 0.9530089153046062 , Val acc 0.8994839578191609, F1-Score 0.8994839578191608\n",
      "Epoch 143/350: Train loss 0.360055148601532, Val loss 0.4086231291294098, Train acc 0.9531017830609212 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 144/350: Train loss 0.35961583256721497, Val loss 0.408792644739151, Train acc 0.9541233283803864 , Val acc 0.9026250841373121, F1-Score 0.9026250841373121\n",
      "Epoch 145/350: Train loss 0.3597337603569031, Val loss 0.40887725353240967, Train acc 0.9537518573551264 , Val acc 0.9030738164684765, F1-Score 0.9030738164684765\n",
      "Epoch 146/350: Train loss 0.36044904589653015, Val loss 0.40915969014167786, Train acc 0.9532875185735513 , Val acc 0.901503253309401, F1-Score 0.901503253309401\n",
      "Epoch 147/350: Train loss 0.36046281456947327, Val loss 0.40919867157936096, Train acc 0.9534732540861813 , Val acc 0.901503253309401, F1-Score 0.901503253309401\n",
      "Epoch 148/350: Train loss 0.3590298295021057, Val loss 0.4092913269996643, Train acc 0.9548662704309064 , Val acc 0.9001570563159076, F1-Score 0.9001570563159076\n",
      "Epoch 149/350: Train loss 0.35861295461654663, Val loss 0.40969744324684143, Train acc 0.9549591381872214 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 150/350: Train loss 0.3580699861049652, Val loss 0.40841588377952576, Train acc 0.9559806835066865 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 151/350: Train loss 0.3588670790195465, Val loss 0.4077587127685547, Train acc 0.9548662704309064 , Val acc 0.9021763518061476, F1-Score 0.9021763518061476\n",
      "Epoch 152/350: Train loss 0.3577026426792145, Val loss 0.40840184688568115, Train acc 0.9559806835066865 , Val acc 0.9010545209782365, F1-Score 0.9010545209782365\n",
      "Epoch 153/350: Train loss 0.3578507602214813, Val loss 0.40990138053894043, Train acc 0.9555163447251115 , Val acc 0.8997083239847431, F1-Score 0.8997083239847431\n",
      "Epoch 154/350: Train loss 0.3572223484516144, Val loss 0.4106542766094208, Train acc 0.9566307578008916 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 155/350: Train loss 0.35712572932243347, Val loss 0.41099849343299866, Train acc 0.9568164933135216 , Val acc 0.8997083239847431, F1-Score 0.8997083239847431\n",
      "Epoch 156/350: Train loss 0.3577175736427307, Val loss 0.412095844745636, Train acc 0.9554234769687965 , Val acc 0.8979133946600852, F1-Score 0.8979133946600852\n",
      "Epoch 157/350: Train loss 0.35625210404396057, Val loss 0.4098028838634491, Train acc 0.9580237741456167 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 158/350: Train loss 0.3570796847343445, Val loss 0.410347580909729, Train acc 0.9565378900445766 , Val acc 0.8992595916535786, F1-Score 0.8992595916535786\n",
      "Epoch 159/350: Train loss 0.3568822741508484, Val loss 0.40964004397392273, Train acc 0.9569093610698366 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 160/350: Train loss 0.35566386580467224, Val loss 0.4092467725276947, Train acc 0.9585809806835067 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 161/350: Train loss 0.35667935013771057, Val loss 0.4115394055843353, Train acc 0.9568164933135216 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 162/350: Train loss 0.3569318950176239, Val loss 0.4051712155342102, Train acc 0.9563521545319466 , Val acc 0.9050931119587167, F1-Score 0.9050931119587167\n",
      "Epoch 163/350: Train loss 0.35622692108154297, Val loss 0.4088776707649231, Train acc 0.9574665676077266 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 164/350: Train loss 0.3557870090007782, Val loss 0.4088074564933777, Train acc 0.9581166419019317 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 165/350: Train loss 0.35618987679481506, Val loss 0.4121191203594208, Train acc 0.9568164933135216 , Val acc 0.8972402961633386, F1-Score 0.8972402961633386\n",
      "Epoch 166/350: Train loss 0.3556126654148102, Val loss 0.41091492772102356, Train acc 0.9577451708766717 , Val acc 0.8997083239847431, F1-Score 0.8997083239847431\n",
      "Epoch 167/350: Train loss 0.3558398187160492, Val loss 0.41329407691955566, Train acc 0.9573736998514116 , Val acc 0.8961184653354274, F1-Score 0.8961184653354274\n",
      "Epoch 168/350: Train loss 0.35548093914985657, Val loss 0.4097680151462555, Train acc 0.9577451708766717 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 169/350: Train loss 0.3559103012084961, Val loss 0.40977799892425537, Train acc 0.9574665676077266 , Val acc 0.9010545209782365, F1-Score 0.9010545209782365\n",
      "Epoch 170/350: Train loss 0.3553461730480194, Val loss 0.41131219267845154, Train acc 0.9580237741456167 , Val acc 0.8990352254879964, F1-Score 0.8990352254879964\n",
      "Epoch 171/350: Train loss 0.3546963930130005, Val loss 0.40873801708221436, Train acc 0.9592310549777118 , Val acc 0.9008301548126543, F1-Score 0.9008301548126543\n",
      "Epoch 172/350: Train loss 0.3547990322113037, Val loss 0.412511944770813, Train acc 0.9585809806835067 , Val acc 0.8958940991698452, F1-Score 0.8958940991698451\n",
      "Epoch 173/350: Train loss 0.3553762435913086, Val loss 0.41073936223983765, Train acc 0.9585809806835067 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 174/350: Train loss 0.35393857955932617, Val loss 0.4111335873603821, Train acc 0.9598811292719168 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 175/350: Train loss 0.3538820743560791, Val loss 0.40967488288879395, Train acc 0.9596025260029718 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 176/350: Train loss 0.353849321603775, Val loss 0.4094863831996918, Train acc 0.9597882615156018 , Val acc 0.8985864931568319, F1-Score 0.8985864931568318\n",
      "Epoch 177/350: Train loss 0.3533579111099243, Val loss 0.41169193387031555, Train acc 0.9606240713224369 , Val acc 0.8983621269912497, F1-Score 0.8983621269912498\n",
      "Epoch 178/350: Train loss 0.35291099548339844, Val loss 0.4114585518836975, Train acc 0.9610884101040119 , Val acc 0.8992595916535786, F1-Score 0.8992595916535786\n",
      "Epoch 179/350: Train loss 0.35315024852752686, Val loss 0.40860506892204285, Train acc 0.9607169390787519 , Val acc 0.9026250841373121, F1-Score 0.9026250841373121\n",
      "Epoch 180/350: Train loss 0.35264208912849426, Val loss 0.40776288509368896, Train acc 0.961552748885587 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 181/350: Train loss 0.3521591126918793, Val loss 0.41030189394950867, Train acc 0.961645616641902 , Val acc 0.8997083239847431, F1-Score 0.8997083239847431\n",
      "Epoch 182/350: Train loss 0.3523692488670349, Val loss 0.4099012315273285, Train acc 0.9612741456166419 , Val acc 0.9001570563159076, F1-Score 0.9001570563159076\n",
      "Epoch 183/350: Train loss 0.35309186577796936, Val loss 0.40815120935440063, Train acc 0.9605312035661219 , Val acc 0.9037469149652232, F1-Score 0.9037469149652232\n",
      "Epoch 184/350: Train loss 0.3532453775405884, Val loss 0.4127635955810547, Train acc 0.9604383358098069 , Val acc 0.8965671976665919, F1-Score 0.8965671976665919\n",
      "Epoch 185/350: Train loss 0.35279330611228943, Val loss 0.4080512821674347, Train acc 0.9613670133729569 , Val acc 0.9026250841373121, F1-Score 0.9026250841373121\n",
      "Epoch 186/350: Train loss 0.3517189025878906, Val loss 0.409006804227829, Train acc 0.962295690936107 , Val acc 0.9024007179717298, F1-Score 0.9024007179717298\n",
      "Epoch 187/350: Train loss 0.352282851934433, Val loss 0.4112483263015747, Train acc 0.9611812778603269 , Val acc 0.9001570563159076, F1-Score 0.9001570563159076\n",
      "Epoch 188/350: Train loss 0.3520532548427582, Val loss 0.41048043966293335, Train acc 0.9614598811292719 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 189/350: Train loss 0.35136619210243225, Val loss 0.40999969840049744, Train acc 0.962295690936107 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 190/350: Train loss 0.35153093934059143, Val loss 0.4094625413417816, Train acc 0.962295690936107 , Val acc 0.8992595916535786, F1-Score 0.8992595916535786\n",
      "Epoch 191/350: Train loss 0.35174760222435, Val loss 0.41006791591644287, Train acc 0.962017087667162 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 192/350: Train loss 0.35169872641563416, Val loss 0.40966495871543884, Train acc 0.962017087667162 , Val acc 0.8997083239847431, F1-Score 0.8997083239847431\n",
      "Epoch 193/350: Train loss 0.3519637882709503, Val loss 0.40906384587287903, Train acc 0.961831352154532 , Val acc 0.9008301548126543, F1-Score 0.9008301548126543\n",
      "Epoch 194/350: Train loss 0.35138577222824097, Val loss 0.411357045173645, Train acc 0.9632243684992571 , Val acc 0.8994839578191609, F1-Score 0.8994839578191608\n",
      "Epoch 195/350: Train loss 0.3516868054866791, Val loss 0.4116942286491394, Train acc 0.962109955423477 , Val acc 0.9001570563159076, F1-Score 0.9001570563159076\n",
      "Epoch 196/350: Train loss 0.35210010409355164, Val loss 0.4104360342025757, Train acc 0.961645616641902 , Val acc 0.8994839578191609, F1-Score 0.8994839578191608\n",
      "Epoch 197/350: Train loss 0.3503173291683197, Val loss 0.40984949469566345, Train acc 0.9634101040118871 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 198/350: Train loss 0.35201793909072876, Val loss 0.4115249514579773, Train acc 0.9613670133729569 , Val acc 0.8974646623289207, F1-Score 0.8974646623289209\n",
      "Epoch 199/350: Train loss 0.3510511517524719, Val loss 0.4132384955883026, Train acc 0.9629457652303121 , Val acc 0.8949966345075163, F1-Score 0.8949966345075163\n",
      "Epoch 200/350: Train loss 0.3509029150009155, Val loss 0.40746816992759705, Train acc 0.9633172362555721 , Val acc 0.9024007179717298, F1-Score 0.9024007179717298\n",
      "Epoch 201/350: Train loss 0.35085684061050415, Val loss 0.4099445343017578, Train acc 0.9631315007429421 , Val acc 0.9008301548126543, F1-Score 0.9008301548126543\n",
      "Epoch 202/350: Train loss 0.3503500819206238, Val loss 0.4107912480831146, Train acc 0.9636887072808321 , Val acc 0.8988108593224142, F1-Score 0.8988108593224142\n",
      "Epoch 203/350: Train loss 0.3502585291862488, Val loss 0.40817928314208984, Train acc 0.9633172362555721 , Val acc 0.9030738164684765, F1-Score 0.9030738164684765\n",
      "Epoch 204/350: Train loss 0.34993961453437805, Val loss 0.4072200357913971, Train acc 0.9635029717682021 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 205/350: Train loss 0.34954017400741577, Val loss 0.41057589650154114, Train acc 0.9640601783060921 , Val acc 0.8997083239847431, F1-Score 0.8997083239847431\n",
      "Epoch 206/350: Train loss 0.35054507851600647, Val loss 0.4094136655330658, Train acc 0.9629457652303121 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 207/350: Train loss 0.35050782561302185, Val loss 0.4117039740085602, Train acc 0.962760029717682 , Val acc 0.8988108593224142, F1-Score 0.8988108593224142\n",
      "Epoch 208/350: Train loss 0.3498120903968811, Val loss 0.41045254468917847, Train acc 0.9636887072808321 , Val acc 0.8990352254879964, F1-Score 0.8990352254879964\n",
      "Epoch 209/350: Train loss 0.3504948914051056, Val loss 0.4115332067012787, Train acc 0.9631315007429421 , Val acc 0.8979133946600852, F1-Score 0.8979133946600852\n",
      "Epoch 210/350: Train loss 0.3501644432544708, Val loss 0.41061270236968994, Train acc 0.9632243684992571 , Val acc 0.9008301548126543, F1-Score 0.9008301548126543\n",
      "Epoch 211/350: Train loss 0.3502900302410126, Val loss 0.41001734137535095, Train acc 0.9635029717682021 , Val acc 0.8994839578191609, F1-Score 0.8994839578191608\n",
      "Epoch 212/350: Train loss 0.35036030411720276, Val loss 0.40837740898132324, Train acc 0.9632243684992571 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 213/350: Train loss 0.3497503399848938, Val loss 0.4130508005619049, Train acc 0.9640601783060921 , Val acc 0.8965671976665919, F1-Score 0.8965671976665919\n",
      "Epoch 214/350: Train loss 0.34937089681625366, Val loss 0.4100255072116852, Train acc 0.9640601783060921 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 215/350: Train loss 0.34907183051109314, Val loss 0.41027358174324036, Train acc 0.9644316493313522 , Val acc 0.9010545209782365, F1-Score 0.9010545209782365\n",
      "Epoch 216/350: Train loss 0.348491370677948, Val loss 0.40982505679130554, Train acc 0.9653603268945022 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 217/350: Train loss 0.34949469566345215, Val loss 0.41129055619239807, Train acc 0.9640601783060921 , Val acc 0.8990352254879964, F1-Score 0.8990352254879964\n",
      "Epoch 218/350: Train loss 0.3490232527256012, Val loss 0.41311779618263245, Train acc 0.9643387815750372 , Val acc 0.8961184653354274, F1-Score 0.8961184653354274\n",
      "Epoch 219/350: Train loss 0.3495599925518036, Val loss 0.4116140604019165, Train acc 0.9641530460624071 , Val acc 0.8985864931568319, F1-Score 0.8985864931568318\n",
      "Epoch 220/350: Train loss 0.34978941082954407, Val loss 0.40832269191741943, Train acc 0.9633172362555721 , Val acc 0.9026250841373121, F1-Score 0.9026250841373121\n",
      "Epoch 221/350: Train loss 0.3483765423297882, Val loss 0.41040828824043274, Train acc 0.9651745913818722 , Val acc 0.8994839578191609, F1-Score 0.8994839578191608\n",
      "Epoch 222/350: Train loss 0.34913334250450134, Val loss 0.41274261474609375, Train acc 0.9648031203566122 , Val acc 0.8979133946600852, F1-Score 0.8979133946600852\n",
      "Epoch 223/350: Train loss 0.34944674372673035, Val loss 0.40975987911224365, Train acc 0.9644316493313522 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 224/350: Train loss 0.34816381335258484, Val loss 0.41240501403808594, Train acc 0.9655460624071323 , Val acc 0.8983621269912497, F1-Score 0.8983621269912498\n",
      "Epoch 225/350: Train loss 0.34780624508857727, Val loss 0.40833577513694763, Train acc 0.9656389301634473 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 226/350: Train loss 0.34921377897262573, Val loss 0.4123412072658539, Train acc 0.9648031203566122 , Val acc 0.8988108593224142, F1-Score 0.8988108593224142\n",
      "Epoch 227/350: Train loss 0.3481667637825012, Val loss 0.4116070568561554, Train acc 0.9655460624071323 , Val acc 0.8988108593224142, F1-Score 0.8988108593224142\n",
      "Epoch 228/350: Train loss 0.3481294810771942, Val loss 0.41449862718582153, Train acc 0.9653603268945022 , Val acc 0.8958940991698452, F1-Score 0.8958940991698451\n",
      "Epoch 229/350: Train loss 0.3483352065086365, Val loss 0.4109598994255066, Train acc 0.9654531946508172 , Val acc 0.8983621269912497, F1-Score 0.8983621269912498\n",
      "Epoch 230/350: Train loss 0.34725165367126465, Val loss 0.412552148103714, Train acc 0.9668462109955424 , Val acc 0.8994839578191609, F1-Score 0.8994839578191608\n",
      "Epoch 231/350: Train loss 0.34854334592819214, Val loss 0.4115224778652191, Train acc 0.9648031203566122 , Val acc 0.897689028494503, F1-Score 0.897689028494503\n",
      "Epoch 232/350: Train loss 0.3476816415786743, Val loss 0.4115045368671417, Train acc 0.9658246656760773 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 233/350: Train loss 0.34781163930892944, Val loss 0.41257867217063904, Train acc 0.9658246656760773 , Val acc 0.8961184653354274, F1-Score 0.8961184653354274\n",
      "Epoch 234/350: Train loss 0.3468356430530548, Val loss 0.41395139694213867, Train acc 0.9673105497771174 , Val acc 0.8949966345075163, F1-Score 0.8949966345075163\n",
      "Epoch 235/350: Train loss 0.3472658097743988, Val loss 0.4095807373523712, Train acc 0.9660104011887073 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 236/350: Train loss 0.3480231761932373, Val loss 0.4113311171531677, Train acc 0.9655460624071323 , Val acc 0.8979133946600852, F1-Score 0.8979133946600852\n",
      "Epoch 237/350: Train loss 0.3473885953426361, Val loss 0.4136173725128174, Train acc 0.9659175334323923 , Val acc 0.8965671976665919, F1-Score 0.8965671976665919\n",
      "Epoch 238/350: Train loss 0.3469330966472626, Val loss 0.41195425391197205, Train acc 0.9666604754829123 , Val acc 0.897689028494503, F1-Score 0.897689028494503\n",
      "Epoch 239/350: Train loss 0.3475700616836548, Val loss 0.4124315679073334, Train acc 0.9661032689450223 , Val acc 0.8965671976665919, F1-Score 0.8965671976665919\n",
      "Epoch 240/350: Train loss 0.34727534651756287, Val loss 0.40938031673431396, Train acc 0.9660104011887073 , Val acc 0.8999326901503253, F1-Score 0.8999326901503253\n",
      "Epoch 241/350: Train loss 0.34651482105255127, Val loss 0.410359263420105, Train acc 0.9667533432392273 , Val acc 0.8992595916535786, F1-Score 0.8992595916535786\n",
      "Epoch 242/350: Train loss 0.3470974862575531, Val loss 0.4094592034816742, Train acc 0.9665676077265973 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 243/350: Train loss 0.34701740741729736, Val loss 0.41204461455345154, Train acc 0.9658246656760773 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 244/350: Train loss 0.34711143374443054, Val loss 0.40847575664520264, Train acc 0.9664747399702823 , Val acc 0.9028494503028943, F1-Score 0.9028494503028943\n",
      "Epoch 245/350: Train loss 0.3466838598251343, Val loss 0.4114728271961212, Train acc 0.9670319465081724 , Val acc 0.8983621269912497, F1-Score 0.8983621269912498\n",
      "Epoch 246/350: Train loss 0.3470110595226288, Val loss 0.4085726737976074, Train acc 0.9665676077265973 , Val acc 0.9028494503028943, F1-Score 0.9028494503028943\n",
      "Epoch 247/350: Train loss 0.3478260040283203, Val loss 0.41140738129615784, Train acc 0.9654531946508172 , Val acc 0.8990352254879964, F1-Score 0.8990352254879964\n",
      "Epoch 248/350: Train loss 0.3475434482097626, Val loss 0.41120705008506775, Train acc 0.9664747399702823 , Val acc 0.8985864931568319, F1-Score 0.8985864931568318\n",
      "Epoch 249/350: Train loss 0.34668251872062683, Val loss 0.4119988679885864, Train acc 0.9666604754829123 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 250/350: Train loss 0.3467666208744049, Val loss 0.4111528694629669, Train acc 0.9666604754829123 , Val acc 0.8985864931568319, F1-Score 0.8985864931568318\n",
      "Epoch 251/350: Train loss 0.34610670804977417, Val loss 0.4099399149417877, Train acc 0.9674962852897474 , Val acc 0.8992595916535786, F1-Score 0.8992595916535786\n",
      "Epoch 252/350: Train loss 0.3456270098686218, Val loss 0.4088480770587921, Train acc 0.9678677563150074 , Val acc 0.9021763518061476, F1-Score 0.9021763518061476\n",
      "Epoch 253/350: Train loss 0.3464808464050293, Val loss 0.4106413722038269, Train acc 0.9665676077265973 , Val acc 0.9001570563159076, F1-Score 0.9001570563159076\n",
      "Epoch 254/350: Train loss 0.3457076847553253, Val loss 0.4110599756240845, Train acc 0.9674034175334324 , Val acc 0.8999326901503253, F1-Score 0.8999326901503253\n",
      "Epoch 255/350: Train loss 0.3455609977245331, Val loss 0.41124457120895386, Train acc 0.9675891530460624 , Val acc 0.9001570563159076, F1-Score 0.9001570563159076\n",
      "Epoch 256/350: Train loss 0.34597575664520264, Val loss 0.41147923469543457, Train acc 0.9675891530460624 , Val acc 0.8990352254879964, F1-Score 0.8990352254879964\n",
      "Epoch 257/350: Train loss 0.3453385829925537, Val loss 0.4090105891227722, Train acc 0.9684249628528975 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 258/350: Train loss 0.34620681405067444, Val loss 0.4103836715221405, Train acc 0.9677748885586924 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 259/350: Train loss 0.3463713526725769, Val loss 0.41004011034965515, Train acc 0.9670319465081724 , Val acc 0.8999326901503253, F1-Score 0.8999326901503253\n",
      "Epoch 260/350: Train loss 0.3458006978034973, Val loss 0.4087194800376892, Train acc 0.9677748885586924 , Val acc 0.9030738164684765, F1-Score 0.9030738164684765\n",
      "Epoch 261/350: Train loss 0.34639132022857666, Val loss 0.41160082817077637, Train acc 0.9669390787518574 , Val acc 0.8988108593224142, F1-Score 0.8988108593224142\n",
      "Epoch 262/350: Train loss 0.3456082046031952, Val loss 0.41022101044654846, Train acc 0.9673105497771174 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 263/350: Train loss 0.3458208739757538, Val loss 0.41059842705726624, Train acc 0.9674962852897474 , Val acc 0.9001570563159076, F1-Score 0.9001570563159076\n",
      "Epoch 264/350: Train loss 0.34579333662986755, Val loss 0.40948399901390076, Train acc 0.9674962852897474 , Val acc 0.901503253309401, F1-Score 0.901503253309401\n",
      "Epoch 265/350: Train loss 0.34453025460243225, Val loss 0.4118790924549103, Train acc 0.9689821693907875 , Val acc 0.8985864931568319, F1-Score 0.8985864931568318\n",
      "Epoch 266/350: Train loss 0.345002681016922, Val loss 0.41071265935897827, Train acc 0.9687035661218425 , Val acc 0.8985864931568319, F1-Score 0.8985864931568318\n",
      "Epoch 267/350: Train loss 0.345843106508255, Val loss 0.41176795959472656, Train acc 0.9674962852897474 , Val acc 0.8990352254879964, F1-Score 0.8990352254879964\n",
      "Epoch 268/350: Train loss 0.34546783566474915, Val loss 0.4081540107727051, Train acc 0.9679606240713224 , Val acc 0.9026250841373121, F1-Score 0.9026250841373121\n",
      "Epoch 269/350: Train loss 0.3455408215522766, Val loss 0.409213125705719, Train acc 0.9679606240713224 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 270/350: Train loss 0.344936728477478, Val loss 0.411783367395401, Train acc 0.9685178306092125 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 271/350: Train loss 0.3454318344593048, Val loss 0.4086184501647949, Train acc 0.9682392273402675 , Val acc 0.9024007179717298, F1-Score 0.9024007179717298\n",
      "Epoch 272/350: Train loss 0.34505632519721985, Val loss 0.40944135189056396, Train acc 0.9686106983655275 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 273/350: Train loss 0.34474167227745056, Val loss 0.41094672679901123, Train acc 0.9684249628528975 , Val acc 0.8983621269912497, F1-Score 0.8983621269912498\n",
      "Epoch 274/350: Train loss 0.34554487466812134, Val loss 0.41007980704307556, Train acc 0.9677748885586924 , Val acc 0.9001570563159076, F1-Score 0.9001570563159076\n",
      "Epoch 275/350: Train loss 0.34505343437194824, Val loss 0.4090692698955536, Train acc 0.9681463595839525 , Val acc 0.9008301548126543, F1-Score 0.9008301548126543\n",
      "Epoch 276/350: Train loss 0.3456387221813202, Val loss 0.4101082980632782, Train acc 0.9676820208023774 , Val acc 0.8997083239847431, F1-Score 0.8997083239847431\n",
      "Epoch 277/350: Train loss 0.34540268778800964, Val loss 0.4098142981529236, Train acc 0.9679606240713224 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 278/350: Train loss 0.34559372067451477, Val loss 0.40707528591156006, Train acc 0.9677748885586924 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 279/350: Train loss 0.3452576994895935, Val loss 0.4076608717441559, Train acc 0.9679606240713224 , Val acc 0.9032981826340588, F1-Score 0.9032981826340588\n",
      "Epoch 280/350: Train loss 0.3455182611942291, Val loss 0.4091827869415283, Train acc 0.9676820208023774 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 281/350: Train loss 0.34380897879600525, Val loss 0.40712013840675354, Train acc 0.9700037147102526 , Val acc 0.9021763518061476, F1-Score 0.9021763518061476\n",
      "Epoch 282/350: Train loss 0.3446255028247833, Val loss 0.4086545705795288, Train acc 0.9692607726597325 , Val acc 0.9024007179717298, F1-Score 0.9024007179717298\n",
      "Epoch 283/350: Train loss 0.34464409947395325, Val loss 0.4109308123588562, Train acc 0.9688893016344725 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 284/350: Train loss 0.34379062056541443, Val loss 0.41050970554351807, Train acc 0.9700965824665676 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 285/350: Train loss 0.34488075971603394, Val loss 0.4096047878265381, Train acc 0.9682392273402675 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 286/350: Train loss 0.3451792597770691, Val loss 0.41000238060951233, Train acc 0.9682392273402675 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 287/350: Train loss 0.34439393877983093, Val loss 0.40759962797164917, Train acc 0.9689821693907875 , Val acc 0.903522548799641, F1-Score 0.903522548799641\n",
      "Epoch 288/350: Train loss 0.3451358675956726, Val loss 0.4079216420650482, Train acc 0.9685178306092125 , Val acc 0.8999326901503253, F1-Score 0.8999326901503253\n",
      "Epoch 289/350: Train loss 0.344956636428833, Val loss 0.4091130793094635, Train acc 0.9681463595839525 , Val acc 0.900605788647072, F1-Score 0.900605788647072\n",
      "Epoch 290/350: Train loss 0.34465208649635315, Val loss 0.4073507785797119, Train acc 0.9686106983655275 , Val acc 0.90442001346197, F1-Score 0.90442001346197\n",
      "Epoch 291/350: Train loss 0.3439261317253113, Val loss 0.4100028872489929, Train acc 0.9690750371471025 , Val acc 0.9008301548126543, F1-Score 0.9008301548126543\n",
      "Epoch 292/350: Train loss 0.34415408968925476, Val loss 0.4101627767086029, Train acc 0.9694465081723626 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 293/350: Train loss 0.3434199094772339, Val loss 0.41112765669822693, Train acc 0.9700965824665676 , Val acc 0.8994839578191609, F1-Score 0.8994839578191608\n",
      "Epoch 294/350: Train loss 0.34490883350372314, Val loss 0.40893855690956116, Train acc 0.9684249628528975 , Val acc 0.9010545209782365, F1-Score 0.9010545209782365\n",
      "Epoch 295/350: Train loss 0.34481024742126465, Val loss 0.409087210893631, Train acc 0.9679606240713224 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 296/350: Train loss 0.34317630529403687, Val loss 0.40795502066612244, Train acc 0.9702823179791976 , Val acc 0.9008301548126543, F1-Score 0.9008301548126543\n",
      "Epoch 297/350: Train loss 0.3435359001159668, Val loss 0.4093533754348755, Train acc 0.9699108469539376 , Val acc 0.901503253309401, F1-Score 0.901503253309401\n",
      "Epoch 298/350: Train loss 0.34486472606658936, Val loss 0.4060923159122467, Train acc 0.9687035661218425 , Val acc 0.9041956472963877, F1-Score 0.9041956472963877\n",
      "Epoch 299/350: Train loss 0.3429005742073059, Val loss 0.41075748205184937, Train acc 0.9705609212481426 , Val acc 0.8985864931568319, F1-Score 0.8985864931568318\n",
      "Epoch 300/350: Train loss 0.3437255322933197, Val loss 0.4098677337169647, Train acc 0.9695393759286776 , Val acc 0.8997083239847431, F1-Score 0.8997083239847431\n",
      "Epoch 301/350: Train loss 0.3433000445365906, Val loss 0.4083463251590729, Train acc 0.9704680534918276 , Val acc 0.9028494503028943, F1-Score 0.9028494503028943\n",
      "Epoch 302/350: Train loss 0.3422915041446686, Val loss 0.40768349170684814, Train acc 0.9712109955423477 , Val acc 0.9028494503028943, F1-Score 0.9028494503028943\n",
      "Epoch 303/350: Train loss 0.3440263867378235, Val loss 0.4102363586425781, Train acc 0.9694465081723626 , Val acc 0.9008301548126543, F1-Score 0.9008301548126543\n",
      "Epoch 304/350: Train loss 0.3441747725009918, Val loss 0.4097467064857483, Train acc 0.9692607726597325 , Val acc 0.9010545209782365, F1-Score 0.9010545209782365\n",
      "Epoch 305/350: Train loss 0.343790203332901, Val loss 0.4112699627876282, Train acc 0.9697251114413076 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 306/350: Train loss 0.3442791700363159, Val loss 0.40842747688293457, Train acc 0.9687964338781575 , Val acc 0.9024007179717298, F1-Score 0.9024007179717298\n",
      "Epoch 307/350: Train loss 0.34356456995010376, Val loss 0.4079572856426239, Train acc 0.9695393759286776 , Val acc 0.903522548799641, F1-Score 0.903522548799641\n",
      "Epoch 308/350: Train loss 0.34339064359664917, Val loss 0.4114234149456024, Train acc 0.9698179791976226 , Val acc 0.8994839578191609, F1-Score 0.8994839578191608\n",
      "Epoch 309/350: Train loss 0.3434503376483917, Val loss 0.40945205092430115, Train acc 0.9697251114413076 , Val acc 0.9010545209782365, F1-Score 0.9010545209782365\n",
      "Epoch 310/350: Train loss 0.342791348695755, Val loss 0.41177207231521606, Train acc 0.9711181277860327 , Val acc 0.8994839578191609, F1-Score 0.8994839578191608\n",
      "Epoch 311/350: Train loss 0.34335505962371826, Val loss 0.4093833267688751, Train acc 0.9700965824665676 , Val acc 0.901503253309401, F1-Score 0.901503253309401\n",
      "Epoch 312/350: Train loss 0.34336209297180176, Val loss 0.4116344451904297, Train acc 0.9698179791976226 , Val acc 0.8994839578191609, F1-Score 0.8994839578191608\n",
      "Epoch 313/350: Train loss 0.34228429198265076, Val loss 0.40755411982536316, Train acc 0.9715824665676077 , Val acc 0.9030738164684765, F1-Score 0.9030738164684765\n",
      "Epoch 314/350: Train loss 0.3427770137786865, Val loss 0.41048896312713623, Train acc 0.9705609212481426 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 315/350: Train loss 0.34243252873420715, Val loss 0.4120520353317261, Train acc 0.9707466567607727 , Val acc 0.8994839578191609, F1-Score 0.8994839578191608\n",
      "Epoch 316/350: Train loss 0.34369564056396484, Val loss 0.4097411632537842, Train acc 0.9690750371471025 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 317/350: Train loss 0.34263601899147034, Val loss 0.40782928466796875, Train acc 0.9711181277860327 , Val acc 0.9028494503028943, F1-Score 0.9028494503028943\n",
      "Epoch 318/350: Train loss 0.3422777056694031, Val loss 0.40940240025520325, Train acc 0.9710252600297177 , Val acc 0.9021763518061476, F1-Score 0.9021763518061476\n",
      "Epoch 319/350: Train loss 0.3432846963405609, Val loss 0.4113149344921112, Train acc 0.9700037147102526 , Val acc 0.8992595916535786, F1-Score 0.8992595916535786\n",
      "Epoch 320/350: Train loss 0.34373939037323, Val loss 0.4114372730255127, Train acc 0.9693536404160475 , Val acc 0.8997083239847431, F1-Score 0.8997083239847431\n",
      "Epoch 321/350: Train loss 0.34295251965522766, Val loss 0.4103240370750427, Train acc 0.9704680534918276 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 322/350: Train loss 0.34383296966552734, Val loss 0.41117721796035767, Train acc 0.9693536404160475 , Val acc 0.8992595916535786, F1-Score 0.8992595916535786\n",
      "Epoch 323/350: Train loss 0.3421083390712738, Val loss 0.4108828008174896, Train acc 0.9714895988112927 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 324/350: Train loss 0.34254932403564453, Val loss 0.41116461157798767, Train acc 0.9705609212481426 , Val acc 0.8992595916535786, F1-Score 0.8992595916535786\n",
      "Epoch 325/350: Train loss 0.3427576422691345, Val loss 0.4116601347923279, Train acc 0.9703751857355126 , Val acc 0.8997083239847431, F1-Score 0.8997083239847431\n",
      "Epoch 326/350: Train loss 0.34335243701934814, Val loss 0.4114565849304199, Train acc 0.9700037147102526 , Val acc 0.8988108593224142, F1-Score 0.8988108593224142\n",
      "Epoch 327/350: Train loss 0.3438602685928345, Val loss 0.4077637791633606, Train acc 0.9691679049034175 , Val acc 0.9024007179717298, F1-Score 0.9024007179717298\n",
      "Epoch 328/350: Train loss 0.34301701188087463, Val loss 0.40883487462997437, Train acc 0.9702823179791976 , Val acc 0.9010545209782365, F1-Score 0.9010545209782365\n",
      "Epoch 329/350: Train loss 0.34231486916542053, Val loss 0.4126094579696655, Train acc 0.9711181277860327 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 330/350: Train loss 0.3425297141075134, Val loss 0.41333550214767456, Train acc 0.9707466567607727 , Val acc 0.8965671976665919, F1-Score 0.8965671976665919\n",
      "Epoch 331/350: Train loss 0.34297072887420654, Val loss 0.4096793532371521, Train acc 0.9703751857355126 , Val acc 0.9003814224814898, F1-Score 0.9003814224814898\n",
      "Epoch 332/350: Train loss 0.3431815505027771, Val loss 0.4084610641002655, Train acc 0.9700965824665676 , Val acc 0.9028494503028943, F1-Score 0.9028494503028943\n",
      "Epoch 333/350: Train loss 0.342663437128067, Val loss 0.408523827791214, Train acc 0.9711181277860327 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 334/350: Train loss 0.34303128719329834, Val loss 0.41254863142967224, Train acc 0.9703751857355126 , Val acc 0.8963428315010097, F1-Score 0.8963428315010097\n",
      "Epoch 335/350: Train loss 0.3431323170661926, Val loss 0.4077955186367035, Train acc 0.9700037147102526 , Val acc 0.9032981826340588, F1-Score 0.9032981826340588\n",
      "Epoch 336/350: Train loss 0.34273195266723633, Val loss 0.4084971249103546, Train acc 0.9707466567607727 , Val acc 0.9026250841373121, F1-Score 0.9026250841373121\n",
      "Epoch 337/350: Train loss 0.3421768248081207, Val loss 0.40921029448509216, Train acc 0.9712109955423477 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 338/350: Train loss 0.3417932391166687, Val loss 0.40923482179641724, Train acc 0.9716753343239227 , Val acc 0.9017276194749831, F1-Score 0.9017276194749831\n",
      "Epoch 339/350: Train loss 0.3417617678642273, Val loss 0.4090288281440735, Train acc 0.9720468053491828 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 340/350: Train loss 0.34277644753456116, Val loss 0.408808171749115, Train acc 0.9706537890044576 , Val acc 0.9019519856405654, F1-Score 0.9019519856405654\n",
      "Epoch 341/350: Train loss 0.3426513671875, Val loss 0.4066883623600006, Train acc 0.9705609212481426 , Val acc 0.9057662104554633, F1-Score 0.9057662104554633\n",
      "Epoch 342/350: Train loss 0.3423888683319092, Val loss 0.40997862815856934, Train acc 0.9709323922734027 , Val acc 0.9012788871438188, F1-Score 0.9012788871438188\n",
      "Epoch 343/350: Train loss 0.3423161804676056, Val loss 0.4083430767059326, Train acc 0.9707466567607727 , Val acc 0.9024007179717298, F1-Score 0.9024007179717298\n",
      "Epoch 344/350: Train loss 0.3421361446380615, Val loss 0.4122394621372223, Train acc 0.9710252600297177 , Val acc 0.8981377608256675, F1-Score 0.8981377608256675\n",
      "Epoch 345/350: Train loss 0.34202247858047485, Val loss 0.4085817337036133, Train acc 0.9716753343239227 , Val acc 0.9024007179717298, F1-Score 0.9024007179717298\n",
      "Epoch 346/350: Train loss 0.342098593711853, Val loss 0.40618374943733215, Train acc 0.9711181277860327 , Val acc 0.9057662104554633, F1-Score 0.9057662104554633\n",
      "Epoch 347/350: Train loss 0.3416648209095001, Val loss 0.4103994071483612, Train acc 0.9718610698365527 , Val acc 0.9008301548126543, F1-Score 0.9008301548126543\n",
      "Epoch 348/350: Train loss 0.34219270944595337, Val loss 0.4087272584438324, Train acc 0.9713967310549777 , Val acc 0.903522548799641, F1-Score 0.903522548799641\n",
      "Epoch 349/350: Train loss 0.34187084436416626, Val loss 0.41231870651245117, Train acc 0.9715824665676077 , Val acc 0.897689028494503, F1-Score 0.897689028494503\n",
      "Epoch 350/350: Train loss 0.34194815158843994, Val loss 0.40864524245262146, Train acc 0.9714895988112927 , Val acc 0.9021763518061476, F1-Score 0.9021763518061476\n",
      "Confusion Matrix :\n",
      "[[2178  234]\n",
      " [ 202 1843]]\n",
      "\n",
      "Epoch 350/350: Train loss 0.34194815158843994, Val loss 0.40864524245262146, Train acc 0.9714895988112927 , Val acc 0.9021763518061476, F1-Score 0.9021763518061476\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = 2\n",
    "X_train, X_val, y_train, y_val = getDataset(dataset)\n",
    "\n",
    "train_data = (X_train,y_train)\n",
    "val_data = (X_val,y_val)\n",
    "\n",
    "\n",
    "input_dim = glove_embeddings.d_emb\n",
    "hidden1_dim = 200\n",
    "hidden2_dim = 100\n",
    "hidden3_dim = 50 \n",
    "drop_out1 = 0.5\n",
    "drop_out2 = 0.5\n",
    "drop_out3 = 0.5\n",
    "num_calsses = 3 if dataset==1 else 2 if dataset==2 else 5\n",
    "\n",
    "\n",
    "epochs = 350\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "\n",
    "model = DANSentimentClassifier(input_dim,hidden1_dim,hidden2_dim,hidden3_dim,drop_out1,drop_out2,drop_out3,num_calsses)\n",
    "\n",
    "\n",
    "train(model,train_data,val_data,epochs,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
